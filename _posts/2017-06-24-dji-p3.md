---
layout:     post
title:      2016 DJI Developper Challenge road to finals
date:       2017-06-24 01:00:00
summary:    How we struggled for the final stretch to the competiton
categories: robotics drones
---

Note: I am now writing thing almost a year later so some of the finer details
have been lost or are a bit fuzzy. In fact, this post will probably be much 
shorter than the previous ones.

End of July not long after we submitted our 3rd round report, [DJI released the
names of the teams](https://developer.dji.com/news/2016-dji-developer-challenge-10-teams-enter-final-round/) 
selected to participate in the final round at Griffis International airport.
We were esctatic to know our hard work had paid off and we were back in the finals
as a revival team. Moreover, we frantically looked all over youtube trying to
find other teams and realized no one else had been able to perform a moving
landing as good as ours. Most teams could at best follow a moving tag or land
on a very slow platform. Our guess is that many teams didn't fully understand 
the implication of having the DJI Guidance attached to the M100 platform. Since
the Guidance give pose estimation to the M100 using downwards facing visual-inertial
odometry, once the drone is on top of the moving platform, the M100's velocity
estimation becomes wrong. Thus, if you attempt to land on the car using velocity
commands, the M100 is unable to follow your commands! Unfortunately, we couldn't
find anything from certain key teams such as Autero, Cardinal SAR (from Stanford)
and Graz Griffins (from TU Graz).

Most teams however had made much progress in the search and rescue aspect of the
competition and had good obstacle avoidance systems that seemed much simpler than
our MoveIt! based system.

This is where we made a key judgement call that ultimately put a lot of strain
on the team. We decided that even though to our knowledge we had the best and
maybe only working moving landing, all teams would eventually be able to catch
up to us in time for finals. That meant we had to invest more time the search
and rescue operation and still keep pushing the landing to make it robust.
In retrospect, only Autero and another team had or were close to having a landing,
that meant that we could have won by completely dropping the search and rescue
mission and focusing everyone on the landing. However, with the information we
had it was be right call.

## Moving away from MoveIt!

Our first order of business was to find a better alternative to MoveIt!. We
had multiple problems with MoveIt! having to do with how ressource costly it is, how most
of our environment could be simplified to 2D and how it didn't fix our problem
of needing an exploration algorithm. After testing a few things including 
ETH-ASL's [Next Best View Planner](https://github.com/ethz-asl/nbvplanner),
we settled on TU Darmstadt's team Hector's [exploration planner](https://github.com/tu-darmstadt-ros-pkg/hector_navigation).
Since an exploration planner tries to get close to unknown space by moving through
free space, it's also an obstacle avoidance module! You can see it working in
the following video

<div class="video-container">
<iframe width="560" height="315" src="https://www.youtube.com/embed/_m04ahrCDoM" frameborder="0" allowfullscreen></iframe>
</div>

We had two major problems with our approach, the first was that we would often
get noise or speckles inserted into our obstacle map. This was due in part to
having our test area up on a hill. This meant that late in the day, our stereo
cameras would look directly at the sun and fasely resolve as an obstacles. No 
matter how much filtering we applied, we couldn't get rid of those speckles.
We had to resolve to some clearing maneuvers if ever the robot got stuck including
doing a 360 on itself and simply clearing a 1m radius around it in the occupation
map.

The second major problem was defining the boundaries for exploration so our drone
didn't go somewhere not in the competition arena. The competitions in which team Hector
participate are SAR scenarions in closed environments with walls around it. 
Unfortunately for us, we had to find some way of inserting a virtual fence for our
robot to stay in. To do this at each iteration, we drew added 

